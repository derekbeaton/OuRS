
## Set up our pipeline to find outliers.
  ## first with the FI & U outliers.

  ## then as a post-hoc way, with robust subspace



rm(list=ls())
## some comparisons & tests.

library(tictoc)
library(ours)
library(GSVD)
library(rrcov)
library(robustbase)
library(cellWise)
library(golubEsets)
library(corrplot)
library(ExPosition)


dist.array.outliers <- function(dist.array, total.dist.cutoff = .95, outlier.cutoff = .95){

  dist.distrs <- sqrt(apply(dist.array^2,c(1,3),sum))
  upper.bound <- sort(c(dist.distrs))[round( length(c(dist.distrs)) * total.dist.cutoff )]

  outlier.scores <- apply(dist.distrs,1,function(x){sum(x >= upper.bound) / length(x)})
  outlier.threshold <- outlier.scores > outlier.cutoff

  return(list(dists=dist.distrs, cut.point = upper.bound, outlier.probabilities = outlier.scores, outliers = outlier.threshold))

}

sh.outliers <- function(sh.out, total.dist.cutoff = .95, outlier.cutoff = .95){

  score.outliers <- dist.array.outliers(sh.out$pred.fi.array,total.dist.cutoff = total.dist.cutoff, outlier.cutoff = outlier.cutoff)
  mahal.outliers <- dist.array.outliers(sh.out$pred.u.array,total.dist.cutoff = total.dist.cutoff, outlier.cutoff = outlier.cutoff)

  return(list(score.outliers=score.outliers,mahal.outliers=mahal.outliers))

}

reproducible.robust.low.rank.rebuild <- function(sh.out, corr.cutoff = NULL){

  # diag(apply(abs(ours.sh.leukdata$loadings.cors),c(1,2),mean))
  # diag(apply(abs(ours.sh.leukdata$loadings.cors),c(1,2),median))
  ## or an alternative would be to find out where the matrix smoothes out.

}

tol.ellipse <- function(dat,ellipse.alpha=.9,mcd.alpha=.9,graphs=F){

  pointsToEllipsoid <- function (X, Sigma, mu)
  {
    if (ncol(Sigma) != nrow(Sigma))
      stop("Sigma must be a square matrix")
    if (ncol(X) != ncol(Sigma))
      stop("number of columns in X must \n                                  be of same dimension as Sigma")
    if (length(mu) != ncol(Sigma))
      stop("length of mu must \n                                  be of same dimension as Sigma")
    eig <- eigen(Sigma)
    SigSqrt = eig$vectors %*% diag(sqrt(eig$values)) %*% t(eig$vectors)
    Z <- t(apply(X, 1, ellipsoidTransform, SigSqrt, mu))
    return(Z)
  }

  ## pTE private function. STOLEN FROM SIBER 2.1.0
  ellipsoidTransform <- function (x, SigSqrt, mu)
  {
    return(solve(SigSqrt, x - mu))
  }

  ## pTE private function. STOLEN FROM SIBER 2.1.0
  ellipseInOut <- function (Z, p = 0.95, r = NULL)
  {
    if (is.null(r)) {
      r <- stats::qchisq(p, df = ncol(Z))
    }
    inside <- rowSums(Z^2) < r
    return(inside)
  }

  addEllipse <- function (mu, sigma, m = NULL, n = 100, p.interval = NULL, ci.mean = FALSE,small.sample = FALSE, do.plot = TRUE, ...)
  {
    if (small.sample & is.null(m))
      message("A sample size number given by m is \n required when small.sample is TRUE")
    if (ci.mean & is.null(m))
      message("A sample size number given by m is \n  required when plotting confidence \n ellipses of the mean with ci.mean is TRUE")
    ifelse(ci.mean, c.scale <- m, c.scale <- 1)
    ifelse(small.sample, q <- (m - 1)/(m - 2), q <- 1)
    ifelse(is.null(p.interval), r <- 1, r <- sqrt(stats::qchisq(p.interval,
                                                                df = 2)))
    e = eigen(sigma/c.scale)
    SigSqrt = e$vectors %*% diag(sqrt(e$values * q)) %*% t(e$vectors)
    cc <- genCircle(n, r)
    back.trans <- function(x) {
      return(SigSqrt %*% x + mu)
    }
    ML.ellipse = t(apply(cc, 1, back.trans))
    if (grDevices::dev.cur() > 1 & do.plot) {
      graphics::lines(ML.ellipse, ...)
    }
    return(ML.ellipse)
  }

  genCircle <- function (n = 100, r)
  {
    theta = seq(0, 2 * pi, length = n)
    x = r * cos(theta)
    y = r * sin(theta)
    return(cbind(x, y))
  }

  #dat <- cbind(od,s.mat.mds)
  ## to get an estimate of just CD v MD robustness.
  mcd <- covMcd(dat,alpha = mcd.alpha)
  mcd.center <- mcd$center
  mcd.cov <- mcd$cov
  data.center <- colMeans(dat)
  data.cov <- cov(dat)

  z1 <- pointsToEllipsoid(dat,mcd.cov,mcd.center)
  z1.outs <- ellipseInOut(z1,p=ellipse.alpha)

  z2 <- pointsToEllipsoid(dat,data.cov,data.center)
  z2.outs <- ellipseInOut(z2,p=ellipse.alpha)


  if(graphs){
    x1 <- c(-max(dat[,1])*.05,max(dat[,1]))*1.1
    y1 <- c(-max(dat[,2])*.05,max(dat[,2]))*1.1


    plot(dat, xlim = x1, ylim = y1,pch=20,col="grey80", main=paste0("Outside of ellipse.alpha = ",ellipse.alpha), xlab="OD", ylab="Sub MD",cex=.5)
    tmp <- addEllipse(mcd.center,mcd.cov,p.interval = ellipse.alpha,col="red",lty=1)
    tmp2 <- addEllipse(data.center,data.cov,p.interval = ellipse.alpha,col="blue",lty=2)
    points(dat[!z1.outs,],bg="red",pch=21,cex=1)
    text(dat[!z1.outs,],labels=rownames(dat[!z1.outs,]),pos=1,col="red")
    points(dat[!z2.outs,],bg="blue",pch=21,cex=1)
    text(dat[!z2.outs,],labels=rownames(dat[!z2.outs,]),pos=1,col="blue")
    legend("bottomright",legend=c("Classic ellipse","Robust ellipse"), col=c("blue","red"), lty=c(2,1))
  }

  return(list(robust.outs=!z1.outs,classic.outs=!z2.outs))

}

data("Golub_Merge")


## from the second-generation p-value paper (see: https://github.com/LucyMcGowan/sgpvalue/blob/master/figures/GolubLeukemiaGeneData.R)
exprsDat <- exprs(Golub_Merge)
N.tmp <- nrow(exprsDat)
NormalizedGeneDat <-  apply(exprsDat, 2, function(z) qnorm((rank(z)-0.5)/N.tmp))
mostExtreme <- which(abs(NormalizedGeneDat) == max(abs(NormalizedGeneDat)))[1]
NormalizedGeneDat <- NormalizedGeneDat[-mostExtreme,]
NormalizedGeneDat_t <- t(NormalizedGeneDat)
N <- nrow(NormalizedGeneDat)
LeukDat <- cbind(NormalizedGeneDat_t,pData(Golub_Merge)[,c('ALL.AML','BM.PB','T.B.cell','Gender','PS','Source')])
hold <- LeukDat[with(LeukDat, order(LeukDat[7129])),]
leukdata <- hold[,-(7129:7134)]



print("START")

print("RRCOV HUBERT GOLUB")
rrcov.hubert.leukdata_tic <- tic()
rrcov.hubert.leukdata <- PcaHubert(leukdata)
rrcov.hubert.leukdata_toc <- toc()

print("OURS SH GOLUB")
ours.sh.leukdata_tic <- tic()
ours.sh.leukdata <- split.half.pca(leukdata,iters = 1000)
ours.sh.leukdata_toc <- toc()

print("END")



score.outlier.info <- dist.array.outliers(ours.sh.leukdata$pred.fi.array[,1:35,])
m.outlier.info <- dist.array.outliers(ours.sh.leukdata$pred.u.array[,1:35,])

score.outlier.info.sub <- dist.array.outliers(ours.sh.leukdata$pred.fi.array[,1:2,])
m.outlier.info.sub <- dist.array.outliers(ours.sh.leukdata$pred.u.array[,1:2,])


## it's clear from here that we really need to capture the wide intervals.
boxplot(t(score.outlier.info$dists[order(apply(score.outlier.info$dists,1,median)),]))
boxplot(t(m.outlier.info$dists[order(apply(m.outlier.info$dists,1,median)),]))

boxplot(t(score.outlier.info.sub$dists[order(apply(score.outlier.info.sub$dists,1,IQR)),]))


boxplot(t(m.outlier.info$dists[order(apply(m.outlier.info$dists,1,IQR)),]))
boxplot(t(m.outlier.info.sub$dists[order(apply(m.outlier.info.sub$dists,1,IQR)),]))


boxplot(t(m.outlier.info$dists[order(apply(m.outlier.info$dists,1,median)),]))



boxplot(t(m.outlier.info$dists[order(apply(m.outlier.info$dists,1,
                                           function(x){
                                             sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
                                           }
                                           )),]))


plot(apply(m.outlier.info$dists,1,median),apply(m.outlier.info$dists,1,IQR))
plot(apply(m.outlier.info.sub$dists,1,median),apply(m.outlier.info.sub$dists,1,IQR))



plot(apply(m.outlier.info$dists,1,median), apply(m.outlier.info$dists,1,
             function(x){
               sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
             }
))


plot(od, apply(m.outlier.info$dists,1,
                                                 function(x){
                                                   sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
                                                 }
))


plot(od, apply(score.outlier.info$dists,1,
               function(x){
                 sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
               }
))


plot(apply(m.outlier.info$dists,1,
           function(x){
             sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
           }
), apply(score.outlier.info$dists,1,
               function(x){
                 sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
               }
))

plot(apply(score.outlier.info$dists,1,median),apply(m.outlier.info$dists,1,median))
plot(apply(score.outlier.info$dists,1,IQR),apply(m.outlier.info$dists,1,IQR))
#plot(apply(score.outlier.info$dists,1,function(x){(sort(x)[round(length(x)*.975)]) - (sort(x)[round(length(x)*.025)])}),apply(m.outlier.info$dists,1,function(x){(sort(x)[round(length(x)*.975)]) - (sort(x)[round(length(x)*.025)])}))


### these all seem very useful right now.
plot(apply(score.outlier.info$dists,1,median),apply(m.outlier.info$dists,1,median))
plot(apply(score.outlier.info.sub$dists,1,median),apply(m.outlier.info.sub$dists,1,median))
plot(apply(score.outlier.info.sub$dists,1,IQR),apply(m.outlier.info.sub$dists,1,IQR))
plot(apply(m.outlier.info$dists,1,IQR),apply(m.outlier.info.sub$dists,1,IQR))

plot(apply(m.outlier.info$dists,1,median),apply(m.outlier.info$dists,1,IQR))
plot(apply(score.outlier.info$dists,1,median),apply(score.outlier.info$dists,1,IQR))

tol.ellipse(cbind(apply(score.outlier.info$dists,1,IQR),apply(m.outlier.info$dists,1,IQR)),graphs=T)


### plot medians; plot IQRs or even quantiles; or even quantiles + median?
    ## that gives a sense of location + scatter?

ours.sh.leukdata2 <- ours.sh.leukdata
ours.sh.leukdata2$pred.fi.array <- ours.sh.leukdata2$pred.fi.array[,1:35,]
ours.sh.leukdata2$pred.u.array <- ours.sh.leukdata2$pred.u.array[,1:35,]

sh.outlier.info <- sh.outliers(ours.sh.leukdata2, total.dist.cutoff = .75)


all.points <- cbind(c(sh.outlier.info$score.outliers$dists),c(sh.outlier.info$mahal.outliers$dists))
plot(0,0,type="n",xlim=c(0,max(all.points[,1])),ylim=c(0,max(all.points[,2])))
abline(v=sh.outlier.info$score.outliers$cut.point,col="olivedrab3")
abline(h=sh.outlier.info$mahal.outliers$cut.point,col="mediumorchid4")
for(i in 1:nrow(sh.outlier.info$score.outliers$dists)){
  this.ob <- cbind(sh.outlier.info$score.outliers$dists[i,],sh.outlier.info$mahal.outliers$dists[i,])

  if(sh.outlier.info$score.outliers$outliers[i]){
    if(sh.outlier.info$mahal.outliers$outliers[i]){
      this.col <- "firebrick3"
    }else{
      this.col <- "olivedrab3"
    }
  }else if(sh.outlier.info$mahal.outliers$outliers[i]){
    this.col <- "mediumorchid4"
  }else{
    this.col <- "grey80"
  }
  peeledHull(this.ob, col=this.col)
}



## number of components requires inspection -- no way around it!
mean.r2.mat <- apply(ours.sh.leukdata$loadings.cors^2,c(1,2),mean)
median.r2.mat <- apply(ours.sh.leukdata$loadings.cors^2,c(1,2),median)
block.r2 <- c()
for(i in 1:nrow(mean.r2.mat)){

  block.r2 <- c(block.r2,mean(c(mean.r2.mat[1:i,1:i])))

}

small.center <- colMeans(leukdata[ours.sh.leukdata$sh1.orders[2,],])

DAT <- expo.scale(leukdata,center=T,scale=F)
full.svd.res <- tolerance.svd(DAT)
low.rank.rebuild <- full.svd.res$u[,1:4] %*% diag(full.svd.res$d[1:4]) %*% t(full.svd.res$v[,1:4])
dumb.rank.rebuild <- full.svd.res$u[,4:length(full.svd.res$d)] %*% diag(full.svd.res$d[4:length(full.svd.res$d)]) %*% t(full.svd.res$v[,4:length(full.svd.res$d)])

s.mat <- DAT - low.rank.rebuild
s.mat.svd <- tolerance.svd(s.mat)

  ## this one is not particularly useful...
    ## in fact, it should just be the inverse of the rebuild from above...
s.mat.mds <- rowSums(s.mat.svd$u^2)
od <- apply(s.mat,1,vecnorm)

tol.ellipse.out <- tol.ellipse(cbind(od,s.mat.mds),graphs=T)



plot(rrcov.hubert.leukdata)


plot(cbind(rrcov.hubert.leukdata@od,od))



epPCA(cbind(apply(score.outlier.info$dists,1,IQR),apply(m.outlier.info$dists,1,IQR),od))





good.fin.dists <- cbind(
                        od,
                        #apply(score.outlier.info$dists,1,median),
                        apply(m.outlier.info$dists,1,median),
                        #apply(score.outlier.info.sub$dists,1,median),
                        apply(m.outlier.info.sub$dists,1,median)
                        #apply(score.outlier.info$dists,1,IQR),            ### could replace with quantile distances.
                        #apply(m.outlier.info$dists,1,IQR),
                        #apply(score.outlier.info.sub$dists,1,IQR),
                        #apply(m.outlier.info.sub$dists,1,IQR)
                        )



better.fin.dists <- cbind(od,
                          apply(m.outlier.info$dists,1,
                                     function(x){
                                       sort(x)[ceiling(length(x)*.975)] - sort(x)[floor(length(x)*.025)]
                                     }
                          ), apply(m.outlier.info$dists,1,
                                   IQR
                          ))



